{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen, Request\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "import datetime\n",
        "\n",
        "# Download the Vader lexicon\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Parameters\n",
        "n = 3\n",
        "tickers = ['AAPL', 'TSLA', 'AMZN', 'MSFT', 'META', 'NVDA', 'GOOGL']\n",
        "\n",
        "# Get Data\n",
        "finwiz_url = 'https://finviz.com/quote.ashx?t='\n",
        "news_tables = {}\n",
        "\n",
        "for ticker in tickers:\n",
        "    url = finwiz_url + ticker\n",
        "    req = Request(url=url, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    resp = urlopen(req)\n",
        "    html = BeautifulSoup(resp, features=\"lxml\")\n",
        "    news_table = html.find(id='news-table')\n",
        "    news_tables[ticker] = news_table\n",
        "    time.sleep(random.randint(1, 3))  # Ajout d'un délai aléatoire entre les requêtes pour éviter le blocage\n",
        "\n",
        "try:\n",
        "    for ticker in tickers:\n",
        "        df = news_tables[ticker]\n",
        "        df_tr = df.findAll('tr')\n",
        "\n",
        "        print ('\\n')\n",
        "        print ('Recent News Headlines for {}: '.format(ticker))\n",
        "\n",
        "        for i, table_row in enumerate(df_tr):\n",
        "            a_text = table_row.a.text\n",
        "            td_text = table_row.td.text\n",
        "            td_text = td_text.strip()\n",
        "            print(a_text,'(',td_text,')')\n",
        "            if i == n-1:\n",
        "                break\n",
        "except KeyError:\n",
        "    pass\n",
        "\n",
        "# Iterate through the news\n",
        "parsed_news = []\n",
        "for file_name, news_table in news_tables.items():\n",
        "    for x in news_table.findAll('tr'):\n",
        "        text = x.a.get_text()\n",
        "        date_scrape = x.td.text.split()\n",
        "\n",
        "        if len(date_scrape) == 1:\n",
        "            time = date_scrape[0]\n",
        "            if time == 'Today':\n",
        "                time = datetime.date.today().strftime('%Y-%m-%d')  # Format the date as YYYY-MM-DD\n",
        "\n",
        "        else:\n",
        "            date = date_scrape[0]\n",
        "            time = date_scrape[1]\n",
        "\n",
        "        ticker = file_name.split('_')[0]\n",
        "\n",
        "        parsed_news.append([ticker, date, time, text])\n",
        "\n",
        "# Sentiment Analysis\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "columns = ['Ticker', 'Date', 'Time', 'Headline']\n",
        "news = pd.DataFrame(parsed_news, columns=columns)\n",
        "scores = news['Headline'].apply(analyzer.polarity_scores).tolist()\n",
        "\n",
        "df_scores = pd.DataFrame(scores)\n",
        "news = news.join(df_scores, rsuffix='_right')\n",
        "\n",
        "\n",
        "# View Data\n",
        "news['Date'] = pd.to_datetime(news.Date, errors='coerce')\n",
        "\n",
        "unique_ticker = news['Ticker'].unique().tolist()\n",
        "news_dict = {name: news.loc[news['Ticker'] == name] for name in unique_ticker}\n",
        "\n",
        "values = []\n",
        "for ticker in tickers:\n",
        "    dataframe = news_dict[ticker]\n",
        "    dataframe = dataframe.set_index('Ticker')\n",
        "    dataframe = dataframe.drop(columns=['Headline'])\n",
        "    print ('\\n')\n",
        "    print (dataframe.head())\n",
        "\n",
        "    mean = round(dataframe['compound'].mean(), 2)\n",
        "    values.append(mean)\n",
        "\n",
        "df = pd.DataFrame(list(zip(tickers, values)), columns=['Ticker', 'Mean Sentiment'])\n",
        "df = df.set_index('Ticker')\n",
        "df = df.sort_values('Mean Sentiment', ascending=False)\n",
        "print ('\\n')\n",
        "print (df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XXaV8RKTRSG",
        "outputId": "6a7e39f8-e720-4cdf-ed33-8a7a7406ca84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Recent News Headlines for AAPL: \n",
            "Warren Buffett Just Revealed the 8 Stocks That Berkshire Hathaway Will Likely Hold Forever -- and Apple Wasn't One of Them ( Today 06:07AM )\n",
            "Apple and Tesla veterans aim to help Japan design AI chips ( 04:35AM )\n",
            "Samsung's XR device expected to enter production before end of 2024 ( Feb-26-24 11:00PM )\n",
            "\n",
            "\n",
            "Recent News Headlines for TSLA: \n",
            "Forget Nvidia: These 3 Artificial Intelligence (AI) Stocks Have Up to 203% Upside, According to Select Wall Street Analysts ( Today 05:21AM )\n",
            "Apple and Tesla veterans aim to help Japan design AI chips ( 04:35AM )\n",
            "Ford halts shipments of popular EV over quality, casts uncertainty ( Feb-26-24 09:31PM )\n",
            "\n",
            "\n",
            "Recent News Headlines for AMZN: \n",
            "Walmart Stock Has 30% Upside, According to 1 Wall Street Analyst ( Today 05:51AM )\n",
            "Numerator Retailer Snapshots: Most U.S. households shop Amazon ( Feb-26-24 06:10PM )\n",
            "Berkshire Hathaway Doesn't Hold Nvidia Stock Will Warren Buffett Come to Regret it? ( 06:00PM )\n",
            "\n",
            "\n",
            "Recent News Headlines for MSFT: \n",
            "Missed Out on Microsoft? This Tiny Cloud Stock Could Deliver Even Bigger Gains. ( Today 06:00AM )\n",
            "1 Overlooked Artificial Intelligence (AI) Stock Taking On Amazon, Microsoft, and Google ( 05:29AM )\n",
            "Microsoft's deal with OpenAI's French rival Mistral faces EU scrutiny ( 05:21AM )\n",
            "\n",
            "\n",
            "Recent News Headlines for META: \n",
            "LG and Meta form AI and metaverse alliance; XR device coming in 1Q25 at the earliest ( Today 01:48AM )\n",
            "UPDATE 2-Meta CEO Zuckerberg meets Japan PM Kishida in Tokyo to discuss AI ( Feb-26-24 10:07PM )\n",
            "Meta CEO Zuckerberg meets Japan PM Kishida in Tokyo to discuss AI ( 09:53PM )\n",
            "\n",
            "\n",
            "Recent News Headlines for NVDA: \n",
            "Nvidia Stock Has 12% Upside, According to 1 Wall Street Analyst ( Today 06:05AM )\n",
            "Forget Nvidia: These 3 Artificial Intelligence (AI) Stocks Have Up to 203% Upside, According to Select Wall Street Analysts ( 05:21AM )\n",
            "Nvidia Stock Gains. Its AI Success Is Sparking a Chips War Among Suppliers. ( 05:02AM )\n",
            "\n",
            "\n",
            "Recent News Headlines for GOOGL: \n",
            "Missed Out on Microsoft? This Tiny Cloud Stock Could Deliver Even Bigger Gains. ( Today 06:00AM )\n",
            "1 Overlooked Artificial Intelligence (AI) Stock Taking On Amazon, Microsoft, and Google ( 05:29AM )\n",
            "3 Reasons Why This \"Magnificent Seven\" Stock Is a Buy ( 03:41AM )\n",
            "\n",
            "\n",
            "             Date     Time    neg    neu    pos  compound\n",
            "Ticker                                                   \n",
            "AAPL          NaT  06:07AM  0.000  1.000  0.000    0.0000\n",
            "AAPL          NaT  04:35AM  0.000  0.787  0.213    0.4019\n",
            "AAPL   2024-02-26  11:00PM  0.000  1.000  0.000    0.0000\n",
            "AAPL   2024-02-26  08:01PM  0.184  0.816  0.000   -0.4019\n",
            "AAPL   2024-02-26  06:02PM  0.000  1.000  0.000    0.0000\n",
            "\n",
            "\n",
            "             Date     Time    neg    neu    pos  compound\n",
            "Ticker                                                   \n",
            "TSLA          NaT  05:21AM  0.090  0.762  0.148    0.2960\n",
            "TSLA          NaT  04:35AM  0.000  0.787  0.213    0.4019\n",
            "TSLA   2024-02-26  09:31PM  0.182  0.606  0.212    0.1027\n",
            "TSLA   2024-02-26  09:24PM  0.000  1.000  0.000    0.0000\n",
            "TSLA   2024-02-26  09:18PM  0.000  0.787  0.213    0.4019\n",
            "\n",
            "\n",
            "             Date     Time    neg    neu    pos  compound\n",
            "Ticker                                                   \n",
            "AMZN          NaT  05:51AM  0.000  1.000  0.000    0.0000\n",
            "AMZN   2024-02-26  06:10PM  0.000  0.805  0.195    0.1779\n",
            "AMZN   2024-02-26  06:00PM  0.189  0.811  0.000   -0.4215\n",
            "AMZN   2024-02-26  05:04PM  0.293  0.707  0.000   -0.4404\n",
            "AMZN   2024-02-26  05:02PM  0.000  1.000  0.000    0.0000\n",
            "\n",
            "\n",
            "       Date     Time    neg    neu    pos  compound\n",
            "Ticker                                             \n",
            "MSFT    NaT  06:00AM  0.141  0.705  0.154    0.0516\n",
            "MSFT    NaT  05:29AM  0.079  0.576  0.345    0.5719\n",
            "MSFT    NaT  05:21AM  0.000  1.000  0.000    0.0000\n",
            "MSFT    NaT  05:18AM  0.000  1.000  0.000    0.0000\n",
            "MSFT    NaT  04:53AM  0.000  1.000  0.000    0.0000\n",
            "\n",
            "\n",
            "             Date     Time  neg  neu  pos  compound\n",
            "Ticker                                             \n",
            "META          NaT  01:48AM  0.0  1.0  0.0       0.0\n",
            "META   2024-02-26  10:07PM  0.0  1.0  0.0       0.0\n",
            "META   2024-02-26  09:53PM  0.0  1.0  0.0       0.0\n",
            "META   2024-02-26  09:34PM  0.0  1.0  0.0       0.0\n",
            "META   2024-02-26  06:03PM  0.0  1.0  0.0       0.0\n",
            "\n",
            "\n",
            "       Date     Time    neg    neu    pos  compound\n",
            "Ticker                                             \n",
            "NVDA    NaT  06:05AM  0.000  1.000  0.000     0.000\n",
            "NVDA    NaT  05:21AM  0.090  0.762  0.148     0.296\n",
            "NVDA    NaT  05:02AM  0.205  0.474  0.321     0.296\n",
            "NVDA    NaT  04:20AM  0.000  1.000  0.000     0.000\n",
            "NVDA    NaT  02:24AM  0.000  1.000  0.000     0.000\n",
            "\n",
            "\n",
            "             Date     Time    neg    neu    pos  compound\n",
            "Ticker                                                   \n",
            "GOOGL         NaT  06:00AM  0.141  0.705  0.154    0.0516\n",
            "GOOGL         NaT  05:29AM  0.079  0.576  0.345    0.5719\n",
            "GOOGL         NaT  03:41AM  0.000  0.642  0.358    0.5994\n",
            "GOOGL  2024-02-26  07:18PM  0.000  1.000  0.000    0.0000\n",
            "GOOGL  2024-02-26  06:36PM  0.000  1.000  0.000    0.0000\n",
            "\n",
            "\n",
            "        Mean Sentiment\n",
            "Ticker                \n",
            "MSFT              0.23\n",
            "AMZN              0.20\n",
            "NVDA              0.20\n",
            "AAPL              0.15\n",
            "META              0.15\n",
            "GOOGL             0.13\n",
            "TSLA              0.02\n"
          ]
        }
      ]
    }
  ]
}